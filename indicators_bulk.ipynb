{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"uploadDir\": \"./data/corpora/deceptive_reviews\",\n",
    "    \"resultDir\": \"./data/results\",\n",
    "    \"optimal_sentence_length\": 16,\n",
    "}\n",
    "\n",
    "indicatorsTemplate = {\n",
    "    \"parsable\": None,\n",
    "    \"confidence_tokenizer\": None,\n",
    "    \"confidence_pos\": None,\n",
    "    \"confidence_ner\": None,\n",
    "    \"confidence_chunker\": None,\n",
    "    \"fit\": None,\n",
    "    \"spelling_mistakes\": None,\n",
    "    \"avg_sentence_len\": None,\n",
    "    \"perc_lowercase\": None,\n",
    "    \"perc_uppercase\": None,\n",
    "    \"lexical_diversity\": None,\n",
    "    \"recognized_by_pos\": None,\n",
    "    \"acronyms\": None,\n",
    "    \"present_in_dictionary\": None,\n",
    "    \"readability_cli\": None,\n",
    "    \"readability_ari\": None,\n",
    "    \"test_avg_sentence_len\": None,\n",
    "    \"test_ari\":None,\n",
    "    \"test_cli\":None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import server\n",
    "import copy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from subprocess import check_output\n",
    "from threading import Thread\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "import enchant\n",
    "from spello.model import SpellCorrectionModel\n",
    "import re\n",
    "import textstat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbiondo\\Anaconda3\\envs\\tesi\\lib\\site-packages\\spello\\model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spello.model.SpellCorrectionModel at 0x2397435bbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpellCorrectionModel(language='en')\n",
    "# sp.load('./spello_model/en_large.pkl')\n",
    "sp.load('./spello_model/en_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list where I'm going to save the indicators for each filename\n",
    "files = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def removePunctuationFromTokenized(contentsTokenized):\n",
    "    excludePuncuation = set(string.punctuation)\n",
    "\n",
    "    # manually add additional punctuation to remove\n",
    "    doubleSingleQuote = '\\'\\''\n",
    "    doubleDash = '--'\n",
    "    doubleTick = '``'\n",
    "\n",
    "    excludePuncuation.add(doubleSingleQuote)\n",
    "    excludePuncuation.add(doubleDash)\n",
    "    excludePuncuation.add(doubleTick)\n",
    "\n",
    "    filteredContents = [\n",
    "        word for word in contentsTokenized if word not in excludePuncuation]\n",
    "    return filteredContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSpellingMistakes(filename, indicator):\n",
    "    with open( os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            corrected = sp.spell_correct(raw_text)\n",
    "            mistakes = 0\n",
    "            for w in text_tokenized:\n",
    "                if(w in corrected['correction_dict']):\n",
    "                    mistakes += 1        \n",
    "            result = (1 - (mistakes / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRecognizedByPOS(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            text_tagged = nltk.pos_tag(text_tokenized, tagset='universal')\n",
    "            unknown = 0\n",
    "            for t in text_tagged:\n",
    "                if t[1] == \"X\":\n",
    "                    unknown += 1\n",
    "            result = (1 - (unknown/len(text_tagged)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(s):\n",
    "    \"\"\"Split sentence s on punctuation\n",
    "    and return number of non-empty words\n",
    "    \"\"\"\n",
    "    punct = r\"\\W\"  # non-word characters\n",
    "    return len([w for w in re.split(punct, s) if w])\n",
    "\n",
    "def computeAvgSentLen(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        terminating_punct = \"[!?.]\"\n",
    "        sentences = [\n",
    "            s.strip()  # without trailing whitespace\n",
    "            for s in re.split(\n",
    "                terminating_punct,\n",
    "                \"\".join(raw_text).replace(\"\\n\", \" \"),  # text as 1 string\n",
    "            )\n",
    "            if s.strip()  # non-empty\n",
    "        ]\n",
    "        # map each sentece to its wordcount then sum all the wordcounts\n",
    "        avgSentenceLength = sum(map(wordcount, sentences)) / len(sentences)\n",
    "        optimalSentenceLen = cfg[\"optimal_sentence_length\"]\n",
    "        if avgSentenceLength > 2*optimalSentenceLen:\n",
    "            avgSentenceLength = 2*optimalSentenceLen\n",
    "        result = (1 - abs(optimalSentenceLen - avgSentenceLength) /\n",
    "                  optimalSentenceLen) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        #this line to get the actual avg sentence lenght not the score\n",
    "        files[filename][\"test_avg_sentence_len\"] = str(avgSentenceLength)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePresentInDictionary(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            correct = 0\n",
    "            for word in text_tokenized:\n",
    "                if d.check(word):\n",
    "                    correct += 1\n",
    "            result = (correct / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLexicalDiversity(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(nltk.word_tokenize(raw_text))\n",
    "\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = (len(set(text_tokenized)) / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setJavaIndicators(filename, result):\n",
    "    files[filename][\"parsable\"] = result[0][0:4]\n",
    "    files[filename][\"confidence_tokenizer\"] = result[1][0:4]\n",
    "    files[filename][\"confidence_pos\"] = result[2][0:4]\n",
    "    files[filename][\"confidence_ner\"] = result[3][0:4]\n",
    "    files[filename][\"confidence_chunker\"] = result[4][0:4]\n",
    "\n",
    "def computeJavaIndicators(filename):\n",
    "    # get the absolute path of the file to pass as argument to jar\n",
    "    path = os.path.abspath(os.path.join(cfg[\"uploadDir\"], filename))\n",
    "    pathModels = os.path.abspath(\"./java-indicators/models\")\n",
    "    # launch java jar\n",
    "    result = check_output(\n",
    "        ['java', '-jar', './java-indicators/java-indicators.jar', path, pathModels])\n",
    "    setJavaIndicators(filename, result.decode().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcronyms(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            acronym_list = re.findall(r\"\\b(?:[0-9]+[A-Z][A-Z0-9]*)|(?:[A-Z][A-Z0-9]+)\\b|\\b[A-Z\\.]{2,}\\b\", raw_text)\n",
    "            #to remove upper case words present in dictionary from the list of acronyms\n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            for acronym in acronym_list:\n",
    "                if d.check(acronym.lower()):\n",
    "                    acronym_list.remove(acronym)\n",
    "            \n",
    "            acronyms_count = 0\n",
    "            for word in text_tokenized:\n",
    "                if word in acronym_list:\n",
    "                    acronyms_count += 1\n",
    "            result = (1-(acronyms_count / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityCli( filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.coleman_liau_index(raw_text)\n",
    "        files[filename][\"test_cli\"] = str(score)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityAri(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.automated_readability_index(raw_text)\n",
    "        files[filename][\"test_ari\"] = str(score)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing deceptive799 | 800 of 800\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "i = 1\n",
    "totalFiles = len(listOfFileNames)\n",
    "for filename in listOfFileNames:\n",
    "    clear_output(wait=False)\n",
    "    print(f\"Analyzing {filename} | {str(i)} of {totalFiles}\")\n",
    "    i += 1\n",
    "    #populate the dictionary\n",
    "    files[filename] = copy.deepcopy(indicatorsTemplate)\n",
    "    computeJavaIndicators(filename)\n",
    "    computeSpellingMistakes(filename,\"spelling_mistakes\")\n",
    "    computeAvgSentLen(filename,\"avg_sentence_len\")\n",
    "    computeLexicalDiversity(filename,\"lexical_diversity\")\n",
    "    computeRecognizedByPOS(filename, \"recognized_by_pos\")\n",
    "    computeAcronyms(filename, \"acronyms\")\n",
    "    computePresentInDictionary(filename,\"present_in_dictionary\")\n",
    "    computeReadabilityCli(filename,\"readability_cli\")\n",
    "    computeReadabilityAri(filename,\"readability_ari\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "indicatorsList = []\n",
    "\n",
    "for f in listOfFileNames:\n",
    "    indicatorsList.append(list(files[f].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>fit</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>perc_lowercase</th>\n",
       "      <th>perc_uppercase</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "      <th>test_avg_sentence_len</th>\n",
       "      <th>test_ari</th>\n",
       "      <th>test_cli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.8</td>\n",
       "      <td>99.8</td>\n",
       "      <td>92.9</td>\n",
       "      <td>99.6</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.7</td>\n",
       "      <td>95.2</td>\n",
       "      <td>99.2</td>\n",
       "      <td>97.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.8</td>\n",
       "      <td>96.6</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>92.8</td>\n",
       "      <td>99.6</td>\n",
       "      <td>93.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.9</td>\n",
       "      <td>79.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>67.8</td>\n",
       "      <td>51.3</td>\n",
       "      <td>19.210526</td>\n",
       "      <td>10.3</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>92.9</td>\n",
       "      <td>99.4</td>\n",
       "      <td>91.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>80.2</td>\n",
       "      <td>73.3</td>\n",
       "      <td>9.363636</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>94.3</td>\n",
       "      <td>99.8</td>\n",
       "      <td>94.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.3</td>\n",
       "      <td>92.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>95.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.6</td>\n",
       "      <td>65.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>99.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>68.6</td>\n",
       "      <td>72.0</td>\n",
       "      <td>14.428571</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>88.8</td>\n",
       "      <td>99.8</td>\n",
       "      <td>95.7</td>\n",
       "      <td>99.3</td>\n",
       "      <td>95.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.1</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>96.5</td>\n",
       "      <td>64.4</td>\n",
       "      <td>72.6</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>94.2</td>\n",
       "      <td>99.2</td>\n",
       "      <td>93.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>95.3</td>\n",
       "      <td>99.4</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>65.9</td>\n",
       "      <td>68.6</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0        88.8                  99.8            92.9            99.6   \n",
       "1       100.0                  99.7            95.2            99.2   \n",
       "2       100.0                  99.5            92.8            99.6   \n",
       "3       100.0                  99.1            92.9            99.4   \n",
       "4       100.0                  99.4            94.3            99.8   \n",
       "..        ...                   ...             ...             ...   \n",
       "795     100.0                  99.3            92.2            99.4   \n",
       "796     100.0                  99.5            93.9            99.6   \n",
       "797      88.8                  99.8            95.7            99.3   \n",
       "798     100.0                  99.8            94.2            99.2   \n",
       "799     100.0                  99.8            95.3            99.4   \n",
       "\n",
       "     confidence_chunker  fit  spelling_mistakes  avg_sentence_len  \\\n",
       "0                  95.0  NaN              100.0              81.9   \n",
       "1                  97.5  NaN               99.0              77.0   \n",
       "2                  93.5  NaN               98.9              79.9   \n",
       "3                  91.9  NaN              100.0              58.5   \n",
       "4                  94.5  NaN              100.0              75.0   \n",
       "..                  ...  ...                ...               ...   \n",
       "795                95.8  NaN              100.0              64.2   \n",
       "796                97.0  NaN              100.0              90.1   \n",
       "797                95.6  NaN               99.1              79.8   \n",
       "798                93.2  NaN              100.0              99.1   \n",
       "799                96.9  NaN               99.0              84.3   \n",
       "\n",
       "     perc_lowercase  perc_uppercase  lexical_diversity  recognized_by_pos  \\\n",
       "0               NaN             NaN               63.3              100.0   \n",
       "1               NaN             NaN               67.2              100.0   \n",
       "2               NaN             NaN               55.8              100.0   \n",
       "3               NaN             NaN               76.4              100.0   \n",
       "4               NaN             NaN               55.0              100.0   \n",
       "..              ...             ...                ...                ...   \n",
       "795             NaN             NaN               81.9              100.0   \n",
       "796             NaN             NaN               72.7              100.0   \n",
       "797             NaN             NaN               67.8              100.0   \n",
       "798             NaN             NaN               62.5              100.0   \n",
       "799             NaN             NaN               77.5              100.0   \n",
       "\n",
       "     acronyms  present_in_dictionary  readability_cli  readability_ari  \\\n",
       "0       100.0                   98.2             59.2             54.0   \n",
       "1       100.0                  100.0             91.8             96.6   \n",
       "2       100.0                   98.9             67.8             51.3   \n",
       "3        98.0                   98.0             80.2             73.3   \n",
       "4       100.0                   98.5             82.0             69.3   \n",
       "..        ...                    ...              ...              ...   \n",
       "795     100.0                   98.6             65.6             80.0   \n",
       "796     100.0                   96.9             68.6             72.0   \n",
       "797      99.1                   96.5             64.4             72.6   \n",
       "798     100.0                  100.0             83.6             76.0   \n",
       "799     100.0                   98.1             65.9             68.6   \n",
       "\n",
       "     test_avg_sentence_len  test_ari  test_cli  \n",
       "0                18.888889       9.9      9.11  \n",
       "1                12.333333       3.5      4.22  \n",
       "2                19.210526      10.3      7.83  \n",
       "3                 9.363636       7.0      5.97  \n",
       "4                20.000000       7.6      5.69  \n",
       "..                     ...       ...       ...  \n",
       "795              10.285714       6.0      8.15  \n",
       "796              14.428571       7.2      7.71  \n",
       "797              12.777778       7.1      8.34  \n",
       "798              15.857143       6.6      5.46  \n",
       "799              13.500000       7.7      8.11  \n",
       "\n",
       "[800 rows x 19 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_df = pd.DataFrame(indicatorsList, columns=list(indicatorsTemplate.keys()))\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 100. strings\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "      <th>test_avg_sentence_len</th>\n",
       "      <th>test_ari</th>\n",
       "      <th>test_cli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.74625</td>\n",
       "      <td>99.52975</td>\n",
       "      <td>92.959875</td>\n",
       "      <td>99.423625</td>\n",
       "      <td>94.009625</td>\n",
       "      <td>98.911875</td>\n",
       "      <td>77.663613</td>\n",
       "      <td>68.404</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.808125</td>\n",
       "      <td>97.807</td>\n",
       "      <td>70.5605</td>\n",
       "      <td>66.130288</td>\n",
       "      <td>16.318313</td>\n",
       "      <td>8.387375</td>\n",
       "      <td>7.410188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0  97.74625              99.52975       92.959875       99.423625   \n",
       "\n",
       "   confidence_chunker  spelling_mistakes  avg_sentence_len  lexical_diversity  \\\n",
       "0           94.009625          98.911875         77.663613             68.404   \n",
       "\n",
       "   recognized_by_pos   acronyms  present_in_dictionary  readability_cli  \\\n",
       "0              99.99  99.808125                 97.807          70.5605   \n",
       "\n",
       "   readability_ari  test_avg_sentence_len  test_ari  test_cli  \n",
       "0        66.130288              16.318313  8.387375  7.410188  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of each column using DataFrame.mean()\n",
    "df2 = ind_df.mean(axis=0).to_frame()\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCsvName = cfg[\"uploadDir\"].replace(\"./data/corpora/\",\"\") + \".csv\"\n",
    "outputPath = os.path.join(cfg[\"resultDir\"],outputCsvName)\n",
    "df2.to_csv(outputPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20cb975c02109accbafa2be35d047791792b4e263bc20b6c63105d80068546e3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tesi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
