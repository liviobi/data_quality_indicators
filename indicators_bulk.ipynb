{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"uploadDir\": \"./data/corpora/nltkCorpus\",\n",
    "    \"resultDir\": \"./data/results\",\n",
    "    \"optimal_sentence_length\": 16,\n",
    "}\n",
    "\n",
    "indicatorsTemplate = {\n",
    "    \"parsable\": None,\n",
    "    \"confidence_tokenizer\": None,\n",
    "    \"confidence_pos\": None,\n",
    "    \"confidence_ner\": None,\n",
    "    \"confidence_chunker\": None,\n",
    "    \"fit\": None,\n",
    "    \"spelling_mistakes\": None,\n",
    "    \"avg_sentence_len\": None,\n",
    "    \"perc_lowercase\": None,\n",
    "    \"perc_uppercase\": None,\n",
    "    \"lexical_diversity\": None,\n",
    "    \"recognized_by_pos\": None,\n",
    "    \"acronyms\": None,\n",
    "    \"present_in_dictionary\": None,\n",
    "    \"readability_cli\": None,\n",
    "    \"readability_ari\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import server\n",
    "import copy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from subprocess import check_output\n",
    "from threading import Thread\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "import enchant\n",
    "from spello.model import SpellCorrectionModel\n",
    "import re\n",
    "import textstat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbiondo\\Anaconda3\\envs\\tesi\\lib\\site-packages\\spello\\model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spello.model.SpellCorrectionModel at 0x247687f4ee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpellCorrectionModel(language='en')\n",
    "# sp.load('./spello_model/en_large.pkl')\n",
    "sp.load('./spello_model/en_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list where I'm going to save the indicators for each filename\n",
    "files = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def removePunctuationFromTokenized(contentsTokenized):\n",
    "    excludePuncuation = set(string.punctuation)\n",
    "\n",
    "    # manually add additional punctuation to remove\n",
    "    doubleSingleQuote = '\\'\\''\n",
    "    doubleDash = '--'\n",
    "    doubleTick = '``'\n",
    "\n",
    "    excludePuncuation.add(doubleSingleQuote)\n",
    "    excludePuncuation.add(doubleDash)\n",
    "    excludePuncuation.add(doubleTick)\n",
    "\n",
    "    filteredContents = [\n",
    "        word for word in contentsTokenized if word not in excludePuncuation]\n",
    "    return filteredContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSpellingMistakes(filename, indicator):\n",
    "    with open( os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            corrected = sp.spell_correct(raw_text)\n",
    "            mistakes = 0\n",
    "            for w in text_tokenized:\n",
    "                if(w in corrected['correction_dict']):\n",
    "                    mistakes += 1        \n",
    "            result = (1 - (mistakes / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRecognizedByPOS(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            text_tagged = nltk.pos_tag(text_tokenized, tagset='universal')\n",
    "            unknown = 0\n",
    "            for t in text_tagged:\n",
    "                if t[1] == \"X\":\n",
    "                    unknown += 1\n",
    "            result = (1 - (unknown/len(text_tagged)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(s):\n",
    "    \"\"\"Split sentence s on punctuation\n",
    "    and return number of non-empty words\n",
    "    \"\"\"\n",
    "    punct = r\"\\W\"  # non-word characters\n",
    "    return len([w for w in re.split(punct, s) if w])\n",
    "\n",
    "def computeAvgSentLen(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        terminating_punct = \"[!?.]\"\n",
    "        sentences = [\n",
    "            s.strip()  # without trailing whitespace\n",
    "            for s in re.split(\n",
    "                terminating_punct,\n",
    "                \"\".join(raw_text).replace(\"\\n\", \" \"),  # text as 1 string\n",
    "            )\n",
    "            if s.strip()  # non-empty\n",
    "        ]\n",
    "        # map each sentece to its wordcount then sum all the wordcounts\n",
    "        avgSentenceLength = sum(map(wordcount, sentences)) / len(sentences)\n",
    "        optimalSentenceLen = cfg[\"optimal_sentence_length\"]\n",
    "        if avgSentenceLength > 2*optimalSentenceLen:\n",
    "            avgSentenceLength = 2*optimalSentenceLen\n",
    "        result = (1 - abs(optimalSentenceLen - avgSentenceLength) /\n",
    "                  optimalSentenceLen) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePresentInDictionary(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            correct = 0\n",
    "            for word in text_tokenized:\n",
    "                if d.check(word):\n",
    "                    correct += 1\n",
    "            result = (correct / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLexicalDiversity(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(nltk.word_tokenize(raw_text))\n",
    "\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = (len(set(text_tokenized)) / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setJavaIndicators(filename, result):\n",
    "    files[filename][\"parsable\"] = result[0][0:4]\n",
    "    files[filename][\"confidence_tokenizer\"] = result[1][0:4]\n",
    "    files[filename][\"confidence_pos\"] = result[2][0:4]\n",
    "    files[filename][\"confidence_ner\"] = result[3][0:4]\n",
    "    files[filename][\"confidence_chunker\"] = result[4][0:4]\n",
    "\n",
    "def computeJavaIndicators(filename):\n",
    "    # get the absolute path of the file to pass as argument to jar\n",
    "    path = os.path.abspath(os.path.join(cfg[\"uploadDir\"], filename))\n",
    "    pathModels = os.path.abspath(\"./java-indicators/models\")\n",
    "    # launch java jar\n",
    "    result = check_output(\n",
    "        ['java', '-jar', './java-indicators/java-indicators.jar', path, pathModels])\n",
    "    setJavaIndicators(filename, result.decode().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcronyms(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            acronym_list = re.findall(r\"\\b(?:[0-9]+[A-Z][A-Z0-9]*)|(?:[A-Z][A-Z0-9]+)\\b|\\b[A-Z\\.]{2,}\\b\", raw_text)\n",
    "            #to remove upper case words present in dictionary from the list of acronyms\n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            for acronym in acronym_list:\n",
    "                if d.check(acronym.lower()):\n",
    "                    acronym_list.remove(acronym)\n",
    "            \n",
    "            acronyms_count = 0\n",
    "            for word in text_tokenized:\n",
    "                if word in acronym_list:\n",
    "                    acronyms_count += 1\n",
    "            result = (1-(acronyms_count / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityCli( filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.coleman_liau_index(raw_text)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityAri(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.automated_readability_index(raw_text)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing wsj_0199 | 199 of 199\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "i = 1\n",
    "totalFiles = len(listOfFileNames)\n",
    "for filename in listOfFileNames:\n",
    "    clear_output(wait=False)\n",
    "    print(f\"Analyzing {filename} | {str(i)} of {totalFiles}\")\n",
    "    i += 1\n",
    "    #populate the dictionary\n",
    "    files[filename] = copy.deepcopy(indicatorsTemplate)\n",
    "    computeJavaIndicators(filename)\n",
    "    computeSpellingMistakes(filename,\"spelling_mistakes\")\n",
    "    computeAvgSentLen(filename,\"avg_sentence_len\")\n",
    "    computeLexicalDiversity(filename,\"lexical_diversity\")\n",
    "    computeRecognizedByPOS(filename, \"recognized_by_pos\")\n",
    "    computeAcronyms(filename, \"acronyms\")\n",
    "    computePresentInDictionary(filename,\"present_in_dictionary\")\n",
    "    computeReadabilityCli(filename,\"readability_cli\")\n",
    "    computeReadabilityAri(filename,\"readability_ari\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "indicatorsList = []\n",
    "\n",
    "for f in listOfFileNames:\n",
    "    indicatorsList.append(list(files[f].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>fit</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>perc_lowercase</th>\n",
       "      <th>perc_uppercase</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>91.6</td>\n",
       "      <td>97.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>96.6</td>\n",
       "      <td>97.6</td>\n",
       "      <td>95.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.6</td>\n",
       "      <td>56.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.6</td>\n",
       "      <td>91.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.2</td>\n",
       "      <td>88.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.1</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>94.5</td>\n",
       "      <td>99.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>97.9</td>\n",
       "      <td>81.4</td>\n",
       "      <td>87.2</td>\n",
       "      <td>95.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>69.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>50.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>94.7</td>\n",
       "      <td>82.5</td>\n",
       "      <td>95.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>86.2</td>\n",
       "      <td>96.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>94.1</td>\n",
       "      <td>90.7</td>\n",
       "      <td>97.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.6</td>\n",
       "      <td>87.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.9</td>\n",
       "      <td>95.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.3</td>\n",
       "      <td>90.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>99.2</td>\n",
       "      <td>98.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.7</td>\n",
       "      <td>37.6</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0       100.0                  99.6            83.9            91.6   \n",
       "1       100.0                  99.8            96.6            97.6   \n",
       "2       100.0                  99.0            93.0            98.0   \n",
       "3       100.0                  99.6            94.5            99.4   \n",
       "4       100.0                  97.9            81.4            87.2   \n",
       "..        ...                   ...             ...             ...   \n",
       "194      50.0                  99.1            94.7            82.5   \n",
       "195     100.0                  99.1            94.1            86.2   \n",
       "196     100.0                  99.2            94.1            90.7   \n",
       "197     100.0                  99.6            91.0            95.9   \n",
       "198     100.0                  98.0            95.8            99.2   \n",
       "\n",
       "     confidence_chunker  fit  spelling_mistakes  avg_sentence_len  \\\n",
       "0                  97.7  NaN               88.4              28.1   \n",
       "1                  95.6  NaN               95.6              56.2   \n",
       "2                  94.9  NaN               97.2              88.7   \n",
       "3                  97.0  NaN               98.5              74.5   \n",
       "4                  95.5  NaN               97.7              22.7   \n",
       "..                  ...  ...                ...               ...   \n",
       "194                95.2  NaN              100.0              75.0   \n",
       "195                96.3  NaN              100.0              75.0   \n",
       "196                97.2  NaN               97.6              87.5   \n",
       "197                95.3  NaN               99.3              90.9   \n",
       "198                98.7  NaN              100.0              47.5   \n",
       "\n",
       "     perc_lowercase  perc_uppercase  lexical_diversity  recognized_by_pos  \\\n",
       "0               NaN             NaN               92.3              100.0   \n",
       "1               NaN             NaN               95.6              100.0   \n",
       "2               NaN             NaN               51.9              100.0   \n",
       "3               NaN             NaN               56.1              100.0   \n",
       "4               NaN             NaN               75.5              100.0   \n",
       "..              ...             ...                ...                ...   \n",
       "194             NaN             NaN               83.3              100.0   \n",
       "195             NaN             NaN               94.4              100.0   \n",
       "196             NaN             NaN               78.5              100.0   \n",
       "197             NaN             NaN               51.8              100.0   \n",
       "198             NaN             NaN               84.2              100.0   \n",
       "\n",
       "     acronyms  present_in_dictionary  readability_cli  readability_ari  \n",
       "0       100.0                   80.7             59.8            61.30  \n",
       "1        95.6                   91.3             11.2             2.00  \n",
       "2       100.0                   95.1             32.8             0.00  \n",
       "3       100.0                   98.2             29.4             0.00  \n",
       "4       100.0                   86.6             65.0            69.30  \n",
       "..        ...                    ...              ...              ...  \n",
       "194     100.0                  100.0             17.4             0.00  \n",
       "195     100.0                   94.4             15.1            16.00  \n",
       "196     100.0                   95.2             14.4             5.99  \n",
       "197     100.0                   99.6             37.9             0.00  \n",
       "198     100.0                   94.7             37.6            36.00  \n",
       "\n",
       "[199 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_df = pd.DataFrame(indicatorsList, columns=list(indicatorsTemplate.keys()))\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 100. strings\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.81407</td>\n",
       "      <td>99.032663</td>\n",
       "      <td>92.731658</td>\n",
       "      <td>97.240201</td>\n",
       "      <td>95.789447</td>\n",
       "      <td>97.943216</td>\n",
       "      <td>72.729648</td>\n",
       "      <td>63.233668</td>\n",
       "      <td>99.99397</td>\n",
       "      <td>99.407035</td>\n",
       "      <td>95.517588</td>\n",
       "      <td>33.727035</td>\n",
       "      <td>8.336784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0  98.81407             99.032663       92.731658       97.240201   \n",
       "\n",
       "   confidence_chunker  spelling_mistakes  avg_sentence_len  lexical_diversity  \\\n",
       "0           95.789447          97.943216         72.729648          63.233668   \n",
       "\n",
       "   recognized_by_pos   acronyms  present_in_dictionary  readability_cli  \\\n",
       "0           99.99397  99.407035              95.517588        33.727035   \n",
       "\n",
       "   readability_ari  \n",
       "0         8.336784  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of each column using DataFrame.mean()\n",
    "df2 = ind_df.mean(axis=0).to_frame()\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCsvName = cfg[\"uploadDir\"].replace(\"./data/corpora/nltkCorpus\",\"\") + \".csv\"\n",
    "outputPath = os.path.join(cfg[\"resultDir\"],outputCsvName)\n",
    "df2.to_csv(outputPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20cb975c02109accbafa2be35d047791792b4e263bc20b6c63105d80068546e3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tesi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
