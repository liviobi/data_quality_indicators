{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"uploadDir\": \"./data/corpora/state_of_the_union_address\",\n",
    "    \"resultDir\": \"./data/results\",\n",
    "    \"optimal_sentence_length\": 16,\n",
    "}\n",
    "\n",
    "indicatorsTemplate = {\n",
    "    \"parsable\": None,\n",
    "    \"confidence_tokenizer\": None,\n",
    "    \"confidence_pos\": None,\n",
    "    \"confidence_ner\": None,\n",
    "    \"confidence_chunker\": None,\n",
    "    \"fit\": None,\n",
    "    \"spelling_mistakes\": None,\n",
    "    \"avg_sentence_len\": None,\n",
    "    \"perc_lowercase\": None,\n",
    "    \"perc_uppercase\": None,\n",
    "    \"lexical_diversity\": None,\n",
    "    \"recognized_by_pos\": None,\n",
    "    \"acronyms\": None,\n",
    "    \"present_in_dictionary\": None,\n",
    "    \"readability_cli\": None,\n",
    "    \"readability_ari\": None,\n",
    "    \"test_avg_sentence_len\": None,\n",
    "    \"test_ari\":None,\n",
    "    \"test_cli\":None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import server\n",
    "import copy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from subprocess import check_output\n",
    "from threading import Thread\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "import enchant\n",
    "from spello.model import SpellCorrectionModel\n",
    "import re\n",
    "import textstat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbiondo\\Anaconda3\\envs\\tesi\\lib\\site-packages\\spello\\model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spello.model.SpellCorrectionModel at 0x188780124a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpellCorrectionModel(language='en')\n",
    "# sp.load('./spello_model/en_large.pkl')\n",
    "sp.load('./spello_model/en_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list where I'm going to save the indicators for each filename\n",
    "files = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def removePunctuationFromTokenized(contentsTokenized):\n",
    "    excludePuncuation = set(string.punctuation)\n",
    "\n",
    "    # manually add additional punctuation to remove\n",
    "    doubleSingleQuote = '\\'\\''\n",
    "    doubleDash = '--'\n",
    "    doubleTick = '``'\n",
    "\n",
    "    excludePuncuation.add(doubleSingleQuote)\n",
    "    excludePuncuation.add(doubleDash)\n",
    "    excludePuncuation.add(doubleTick)\n",
    "\n",
    "    filteredContents = [\n",
    "        word for word in contentsTokenized if word not in excludePuncuation]\n",
    "    return filteredContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSpellingMistakes(filename, indicator):\n",
    "    with open( os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            corrected = sp.spell_correct(raw_text)\n",
    "            mistakes = 0\n",
    "            for w in text_tokenized:\n",
    "                if(w in corrected['correction_dict']):\n",
    "                    mistakes += 1        \n",
    "            result = (1 - (mistakes / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRecognizedByPOS(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            text_tagged = nltk.pos_tag(text_tokenized, tagset='universal')\n",
    "            unknown = 0\n",
    "            for t in text_tagged:\n",
    "                if t[1] == \"X\":\n",
    "                    unknown += 1\n",
    "            result = (1 - (unknown/len(text_tagged)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(s):\n",
    "    \"\"\"Split sentence s on punctuation\n",
    "    and return number of non-empty words\n",
    "    \"\"\"\n",
    "    punct = r\"\\W\"  # non-word characters\n",
    "    return len([w for w in re.split(punct, s) if w])\n",
    "\n",
    "def computeAvgSentLen(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        terminating_punct = \"[!?.]\"\n",
    "        sentences = [\n",
    "            s.strip()  # without trailing whitespace\n",
    "            for s in re.split(\n",
    "                terminating_punct,\n",
    "                \"\".join(raw_text).replace(\"\\n\", \" \"),  # text as 1 string\n",
    "            )\n",
    "            if s.strip()  # non-empty\n",
    "        ]\n",
    "        # map each sentece to its wordcount then sum all the wordcounts\n",
    "        avgSentenceLength = sum(map(wordcount, sentences)) / len(sentences)\n",
    "        optimalSentenceLen = cfg[\"optimal_sentence_length\"]\n",
    "        if avgSentenceLength > 2*optimalSentenceLen:\n",
    "            avgSentenceLength = 2*optimalSentenceLen\n",
    "        result = (1 - abs(optimalSentenceLen - avgSentenceLength) /\n",
    "                  optimalSentenceLen) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        #this line to get the actual avg sentence lenght not the score\n",
    "        files[filename][\"test_avg_sentence_len\"] = str(avgSentenceLength)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePresentInDictionary(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            correct = 0\n",
    "            for word in text_tokenized:\n",
    "                if d.check(word):\n",
    "                    correct += 1\n",
    "            result = (correct / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLexicalDiversity(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(nltk.word_tokenize(raw_text))\n",
    "\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = (len(set(text_tokenized)) / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setJavaIndicators(filename, result):\n",
    "    files[filename][\"parsable\"] = result[0][0:4]\n",
    "    files[filename][\"confidence_tokenizer\"] = result[1][0:4]\n",
    "    files[filename][\"confidence_pos\"] = result[2][0:4]\n",
    "    files[filename][\"confidence_ner\"] = result[3][0:4]\n",
    "    files[filename][\"confidence_chunker\"] = result[4][0:4]\n",
    "\n",
    "def computeJavaIndicators(filename):\n",
    "    # get the absolute path of the file to pass as argument to jar\n",
    "    path = os.path.abspath(os.path.join(cfg[\"uploadDir\"], filename))\n",
    "    pathModels = os.path.abspath(\"./java-indicators/models\")\n",
    "    # launch java jar\n",
    "    result = check_output(\n",
    "        ['java', '-jar', './java-indicators/java-indicators.jar', path, pathModels])\n",
    "    setJavaIndicators(filename, result.decode().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcronyms(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            acronym_list = re.findall(r\"\\b(?:[0-9]+[A-Z][A-Z0-9]*)|(?:[A-Z][A-Z0-9]+)\\b|\\b[A-Z\\.]{2,}\\b\", raw_text)\n",
    "            #to remove upper case words present in dictionary from the list of acronyms\n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            for acronym in acronym_list:\n",
    "                if d.check(acronym.lower()):\n",
    "                    acronym_list.remove(acronym)\n",
    "            \n",
    "            acronyms_count = 0\n",
    "            for word in text_tokenized:\n",
    "                if word in acronym_list:\n",
    "                    acronyms_count += 1\n",
    "            result = (1-(acronyms_count / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityCli( filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.coleman_liau_index(raw_text)\n",
    "        files[filename][\"test_cli\"] = str(score)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityAri(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\",errors='backslashreplace') as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.automated_readability_index(raw_text)\n",
    "        files[filename][\"test_ari\"] = str(score)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Wilson_1920.txt | 227 of 227\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "i = 1\n",
    "totalFiles = len(listOfFileNames)\n",
    "for filename in listOfFileNames:\n",
    "    clear_output(wait=False)\n",
    "    print(f\"Analyzing {filename} | {str(i)} of {totalFiles}\")\n",
    "    i += 1\n",
    "    #populate the dictionary\n",
    "    files[filename] = copy.deepcopy(indicatorsTemplate)\n",
    "    computeJavaIndicators(filename)\n",
    "    computeSpellingMistakes(filename,\"spelling_mistakes\")\n",
    "    computeAvgSentLen(filename,\"avg_sentence_len\")\n",
    "    computeLexicalDiversity(filename,\"lexical_diversity\")\n",
    "    computeRecognizedByPOS(filename, \"recognized_by_pos\")\n",
    "    computeAcronyms(filename, \"acronyms\")\n",
    "    computePresentInDictionary(filename,\"present_in_dictionary\")\n",
    "    computeReadabilityCli(filename,\"readability_cli\")\n",
    "    computeReadabilityAri(filename,\"readability_ari\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "indicatorsList = []\n",
    "\n",
    "for f in listOfFileNames:\n",
    "    indicatorsList.append(list(files[f].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>fit</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>perc_lowercase</th>\n",
       "      <th>perc_uppercase</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "      <th>test_avg_sentence_len</th>\n",
       "      <th>test_ari</th>\n",
       "      <th>test_cli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.7</td>\n",
       "      <td>99.7</td>\n",
       "      <td>90.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>90.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2</td>\n",
       "      <td>99.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.5</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.4</td>\n",
       "      <td>99.7</td>\n",
       "      <td>90.7</td>\n",
       "      <td>99.5</td>\n",
       "      <td>91.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.3</td>\n",
       "      <td>12.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.8</td>\n",
       "      <td>99.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>99.7</td>\n",
       "      <td>91.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>33.2</td>\n",
       "      <td>13.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.1</td>\n",
       "      <td>99.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>90.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>31.5</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.2</td>\n",
       "      <td>99.7</td>\n",
       "      <td>91.1</td>\n",
       "      <td>99.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.3</td>\n",
       "      <td>12.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>96.6</td>\n",
       "      <td>99.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>50.8</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>95.6</td>\n",
       "      <td>99.8</td>\n",
       "      <td>90.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>90.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.8</td>\n",
       "      <td>52.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.521739</td>\n",
       "      <td>20.5</td>\n",
       "      <td>10.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>96.6</td>\n",
       "      <td>99.7</td>\n",
       "      <td>90.8</td>\n",
       "      <td>99.5</td>\n",
       "      <td>90.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>96.4</td>\n",
       "      <td>99.8</td>\n",
       "      <td>90.7</td>\n",
       "      <td>99.5</td>\n",
       "      <td>90.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.475309</td>\n",
       "      <td>20.1</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>97.8</td>\n",
       "      <td>99.6</td>\n",
       "      <td>89.7</td>\n",
       "      <td>99.3</td>\n",
       "      <td>90.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.7</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>27.8</td>\n",
       "      <td>12.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0        96.7                  99.7            90.2            99.4   \n",
       "1        96.4                  99.7            90.7            99.5   \n",
       "2        94.8                  99.8            92.0            99.7   \n",
       "3        95.1                  99.8            90.9            99.7   \n",
       "4        97.2                  99.7            91.1            99.6   \n",
       "..        ...                   ...             ...             ...   \n",
       "222      96.6                  99.8            92.0            99.6   \n",
       "223      95.6                  99.8            90.2            99.4   \n",
       "224      96.6                  99.7            90.8            99.5   \n",
       "225      96.4                  99.8            90.7            99.5   \n",
       "226      97.8                  99.6            89.7            99.3   \n",
       "\n",
       "     confidence_chunker  fit  spelling_mistakes  avg_sentence_len  \\\n",
       "0                  90.8  NaN               99.5               0.0   \n",
       "1                  91.3  NaN               99.4               0.0   \n",
       "2                  91.6  NaN               99.4               0.0   \n",
       "3                  90.8  NaN               99.5               0.0   \n",
       "4                  91.5  NaN               99.4               0.0   \n",
       "..                  ...  ...                ...               ...   \n",
       "222                90.5  NaN               99.4               0.0   \n",
       "223                90.4  NaN               99.4              21.7   \n",
       "224                90.4  NaN               99.5               0.0   \n",
       "225                90.6  NaN               99.6              15.7   \n",
       "226                90.4  NaN               99.7               0.0   \n",
       "\n",
       "     perc_lowercase  perc_uppercase  lexical_diversity  recognized_by_pos  \\\n",
       "0               NaN             NaN               35.2               99.9   \n",
       "1               NaN             NaN               37.2              100.0   \n",
       "2               NaN             NaN               39.4              100.0   \n",
       "3               NaN             NaN               40.5              100.0   \n",
       "4               NaN             NaN               23.6              100.0   \n",
       "..              ...             ...                ...                ...   \n",
       "222             NaN             NaN               33.8              100.0   \n",
       "223             NaN             NaN               28.2              100.0   \n",
       "224             NaN             NaN               26.8              100.0   \n",
       "225             NaN             NaN               29.2              100.0   \n",
       "226             NaN             NaN               33.4              100.0   \n",
       "\n",
       "     acronyms  present_in_dictionary  readability_cli  readability_ari  \\\n",
       "0       100.0                   99.9             34.0              0.0   \n",
       "1       100.0                   99.6             34.4              0.0   \n",
       "2       100.0                  100.0             31.3              0.0   \n",
       "3       100.0                   99.9             32.4              0.0   \n",
       "4        99.9                   99.7             36.3              0.0   \n",
       "..        ...                    ...              ...              ...   \n",
       "222      99.9                   99.7             32.0              0.0   \n",
       "223      99.9                   99.8             52.2              0.0   \n",
       "224      99.9                   99.7             46.0              0.0   \n",
       "225      99.9                   99.7             37.9              0.0   \n",
       "226      99.9                   99.7             37.8              0.0   \n",
       "\n",
       "     test_avg_sentence_len  test_ari  test_cli  \n",
       "0                32.000000      28.5     12.90  \n",
       "1                32.000000      34.3     12.84  \n",
       "2                32.000000      33.2     13.30  \n",
       "3                32.000000      31.5     13.13  \n",
       "4                32.000000      32.3     12.55  \n",
       "..                     ...       ...       ...  \n",
       "222              32.000000      50.8     13.19  \n",
       "223              28.521739      20.5     10.17  \n",
       "224              32.000000      22.0     11.10  \n",
       "225              29.475309      20.1     12.31  \n",
       "226              32.000000      27.8     12.32  \n",
       "\n",
       "[227 rows x 19 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_df = pd.DataFrame(indicatorsList, columns=list(indicatorsTemplate.keys()))\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 100. strings\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "      <th>test_avg_sentence_len</th>\n",
       "      <th>test_ari</th>\n",
       "      <th>test_cli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.244053</td>\n",
       "      <td>99.611454</td>\n",
       "      <td>90.463436</td>\n",
       "      <td>99.291189</td>\n",
       "      <td>91.081498</td>\n",
       "      <td>99.529075</td>\n",
       "      <td>33.360661</td>\n",
       "      <td>26.921586</td>\n",
       "      <td>99.96696</td>\n",
       "      <td>99.880617</td>\n",
       "      <td>99.457269</td>\n",
       "      <td>37.929515</td>\n",
       "      <td>3.736344</td>\n",
       "      <td>26.652513</td>\n",
       "      <td>28.003084</td>\n",
       "      <td>12.304626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0  97.244053             99.611454       90.463436       99.291189   \n",
       "\n",
       "   confidence_chunker  spelling_mistakes  avg_sentence_len  lexical_diversity  \\\n",
       "0           91.081498          99.529075         33.360661          26.921586   \n",
       "\n",
       "   recognized_by_pos   acronyms  present_in_dictionary  readability_cli  \\\n",
       "0           99.96696  99.880617              99.457269        37.929515   \n",
       "\n",
       "   readability_ari  test_avg_sentence_len   test_ari   test_cli  \n",
       "0         3.736344              26.652513  28.003084  12.304626  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of each column using DataFrame.mean()\n",
    "df2 = ind_df.mean(axis=0).to_frame()\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCsvName = cfg[\"uploadDir\"].replace(\"./data/corpora/\",\"\") + \".csv\"\n",
    "outputPath = os.path.join(cfg[\"resultDir\"],outputCsvName)\n",
    "df2.to_csv(outputPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20cb975c02109accbafa2be35d047791792b4e263bc20b6c63105d80068546e3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tesi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
