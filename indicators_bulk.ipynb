{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"uploadDir\": \"./data/corpora/sms_spam/ham\",\n",
    "    \"resultDir\": \"./data/results\",\n",
    "    \"optimal_sentence_length\": 16,\n",
    "}\n",
    "\n",
    "indicatorsTemplate = {\n",
    "    \"parsable\": None,\n",
    "    \"confidence_tokenizer\": None,\n",
    "    \"confidence_pos\": None,\n",
    "    \"confidence_ner\": None,\n",
    "    \"confidence_chunker\": None,\n",
    "    \"fit\": None,\n",
    "    \"spelling_mistakes\": None,\n",
    "    \"avg_sentence_len\": None,\n",
    "    \"perc_lowercase\": None,\n",
    "    \"perc_uppercase\": None,\n",
    "    \"lexical_diversity\": None,\n",
    "    \"recognized_by_pos\": None,\n",
    "    \"acronyms\": None,\n",
    "    \"present_in_dictionary\": None,\n",
    "    \"readability_cli\": None,\n",
    "    \"readability_ari\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import server\n",
    "import copy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from subprocess import check_output\n",
    "from threading import Thread\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "import enchant\n",
    "from spello.model import SpellCorrectionModel\n",
    "import re\n",
    "import textstat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbiondo\\Anaconda3\\envs\\tesi\\lib\\site-packages\\spello\\model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spello.model.SpellCorrectionModel at 0x1fa252ee0e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpellCorrectionModel(language='en')\n",
    "# sp.load('./spello_model/en_large.pkl')\n",
    "sp.load('./spello_model/en_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list where I'm going to save the indicators for each filename\n",
    "files = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def removePunctuationFromTokenized(contentsTokenized):\n",
    "    excludePuncuation = set(string.punctuation)\n",
    "\n",
    "    # manually add additional punctuation to remove\n",
    "    doubleSingleQuote = '\\'\\''\n",
    "    doubleDash = '--'\n",
    "    doubleTick = '``'\n",
    "\n",
    "    excludePuncuation.add(doubleSingleQuote)\n",
    "    excludePuncuation.add(doubleDash)\n",
    "    excludePuncuation.add(doubleTick)\n",
    "\n",
    "    filteredContents = [\n",
    "        word for word in contentsTokenized if word not in excludePuncuation]\n",
    "    return filteredContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSpellingMistakes(filename, indicator):\n",
    "    with open( os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            corrected = sp.spell_correct(raw_text)\n",
    "            mistakes = 0\n",
    "            for w in text_tokenized:\n",
    "                if(w in corrected['correction_dict']):\n",
    "                    mistakes += 1        \n",
    "            result = (1 - (mistakes / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRecognizedByPOS(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            text_tagged = nltk.pos_tag(text_tokenized, tagset='universal')\n",
    "            unknown = 0\n",
    "            for t in text_tagged:\n",
    "                if t[1] == \"X\":\n",
    "                    unknown += 1\n",
    "            result = (1 - (unknown/len(text_tagged)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(s):\n",
    "    \"\"\"Split sentence s on punctuation\n",
    "    and return number of non-empty words\n",
    "    \"\"\"\n",
    "    punct = r\"\\W\"  # non-word characters\n",
    "    return len([w for w in re.split(punct, s) if w])\n",
    "\n",
    "def computeAvgSentLen(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        terminating_punct = \"[!?.]\"\n",
    "        sentences = [\n",
    "            s.strip()  # without trailing whitespace\n",
    "            for s in re.split(\n",
    "                terminating_punct,\n",
    "                \"\".join(raw_text).replace(\"\\n\", \" \"),  # text as 1 string\n",
    "            )\n",
    "            if s.strip()  # non-empty\n",
    "        ]\n",
    "        # map each sentece to its wordcount then sum all the wordcounts\n",
    "        avgSentenceLength = sum(map(wordcount, sentences)) / len(sentences)\n",
    "        optimalSentenceLen = cfg[\"optimal_sentence_length\"]\n",
    "        if avgSentenceLength > 2*optimalSentenceLen:\n",
    "            avgSentenceLength = 2*optimalSentenceLen\n",
    "        result = (1 - abs(optimalSentenceLen - avgSentenceLength) /\n",
    "                  optimalSentenceLen) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePresentInDictionary(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            correct = 0\n",
    "            for word in text_tokenized:\n",
    "                if d.check(word):\n",
    "                    correct += 1\n",
    "            result = (correct / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLexicalDiversity(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(nltk.word_tokenize(raw_text))\n",
    "\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = (len(set(text_tokenized)) / len(text_tokenized))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setJavaIndicators(filename, result):\n",
    "    files[filename][\"parsable\"] = result[0][0:4]\n",
    "    files[filename][\"confidence_tokenizer\"] = result[1][0:4]\n",
    "    files[filename][\"confidence_pos\"] = result[2][0:4]\n",
    "    files[filename][\"confidence_ner\"] = result[3][0:4]\n",
    "    files[filename][\"confidence_chunker\"] = result[4][0:4]\n",
    "\n",
    "def computeJavaIndicators(filename):\n",
    "    # get the absolute path of the file to pass as argument to jar\n",
    "    path = os.path.abspath(os.path.join(cfg[\"uploadDir\"], filename))\n",
    "    pathModels = os.path.abspath(\"./java-indicators/models\")\n",
    "    # launch java jar\n",
    "    result = check_output(\n",
    "        ['java', '-jar', './java-indicators/java-indicators.jar', path, pathModels])\n",
    "    setJavaIndicators(filename, result.decode().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcronyms(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        text_tokenized = removePunctuationFromTokenized(\n",
    "            nltk.word_tokenize(raw_text))\n",
    "        if len(text_tokenized) == 0:\n",
    "            result = 0\n",
    "        else:    \n",
    "            acronym_list = re.findall(r\"\\b(?:[0-9]+[A-Z][A-Z0-9]*)|(?:[A-Z][A-Z0-9]+)\\b|\\b[A-Z\\.]{2,}\\b\", raw_text)\n",
    "            #to remove upper case words present in dictionary from the list of acronyms\n",
    "            d = enchant.Dict(\"en_US\")\n",
    "            for acronym in acronym_list:\n",
    "                if d.check(acronym.lower()):\n",
    "                    acronym_list.remove(acronym)\n",
    "            \n",
    "            acronyms_count = 0\n",
    "            for word in text_tokenized:\n",
    "                if word in acronym_list:\n",
    "                    acronyms_count += 1\n",
    "            result = (1-(acronyms_count / len(text_tokenized)))*100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityCli( filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.coleman_liau_index(raw_text)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeReadabilityAri(filename, indicator):\n",
    "    with open(os.path.join(cfg[\"uploadDir\"], filename), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "        score = textstat.automated_readability_index(raw_text)\n",
    "        optimalScore = 3\n",
    "        worstScore = 18\n",
    "\n",
    "        if(score > worstScore):\n",
    "            score = worstScore\n",
    "\n",
    "        result = (1 - abs(optimalScore - score) /\n",
    "                  (worstScore - optimalScore)) * 100\n",
    "        files[filename][indicator] = str(result)[0:4]\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing ham_999 | 4613 of 4613\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "i = 1\n",
    "totalFiles = len(listOfFileNames)\n",
    "for filename in listOfFileNames:\n",
    "    clear_output(wait=False)\n",
    "    print(f\"Analyzing {filename} | {str(i)} of {totalFiles}\")\n",
    "    i += 1\n",
    "    #populate the dictionary\n",
    "    files[filename] = copy.deepcopy(indicatorsTemplate)\n",
    "    computeJavaIndicators(filename)\n",
    "    computeSpellingMistakes(filename,\"spelling_mistakes\")\n",
    "    computeAvgSentLen(filename,\"avg_sentence_len\")\n",
    "    computeLexicalDiversity(filename,\"lexical_diversity\")\n",
    "    computeRecognizedByPOS(filename, \"recognized_by_pos\")\n",
    "    computeAcronyms(filename, \"acronyms\")\n",
    "    computePresentInDictionary(filename,\"present_in_dictionary\")\n",
    "    computeReadabilityCli(filename,\"readability_cli\")\n",
    "    computeReadabilityAri(filename,\"readability_ari\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFileNames = [fileName for fileName in listdir(cfg[\"uploadDir\"]) if isfile(join(cfg[\"uploadDir\"], fileName))]\n",
    "\n",
    "indicatorsList = []\n",
    "\n",
    "for f in listOfFileNames:\n",
    "    indicatorsList.append(list(files[f].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>fit</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>perc_lowercase</th>\n",
       "      <th>perc_uppercase</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>91.9</td>\n",
       "      <td>74.9</td>\n",
       "      <td>99.8</td>\n",
       "      <td>84.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.3</td>\n",
       "      <td>41.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.6</td>\n",
       "      <td>95.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.9</td>\n",
       "      <td>92.5</td>\n",
       "      <td>94.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>72.5</td>\n",
       "      <td>98.7</td>\n",
       "      <td>88.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>63.6</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>74.5</td>\n",
       "      <td>99.1</td>\n",
       "      <td>85.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>68.4</td>\n",
       "      <td>97.5</td>\n",
       "      <td>91.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>81.6</td>\n",
       "      <td>91.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>94.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>100.0</td>\n",
       "      <td>92.6</td>\n",
       "      <td>77.9</td>\n",
       "      <td>98.4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>92.8</td>\n",
       "      <td>52.6</td>\n",
       "      <td>43.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>88.9</td>\n",
       "      <td>98.9</td>\n",
       "      <td>96.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>78.3</td>\n",
       "      <td>98.9</td>\n",
       "      <td>98.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>76.7</td>\n",
       "      <td>98.6</td>\n",
       "      <td>92.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.8</td>\n",
       "      <td>77.3</td>\n",
       "      <td>77.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>98.9</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>62.2</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4613 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0        100.0                  91.9            74.9            99.8   \n",
       "1        100.0                  79.1            72.5            98.7   \n",
       "2        100.0                  98.2            74.5            99.1   \n",
       "3        100.0                  99.2            68.4            97.5   \n",
       "4        100.0                  99.8            88.0            97.5   \n",
       "...        ...                   ...             ...             ...   \n",
       "4608     100.0                  92.6            77.9            98.4   \n",
       "4609     100.0                  99.6            88.9            98.9   \n",
       "4610     100.0                  98.8            78.3            98.9   \n",
       "4611     100.0                  99.4            76.7            98.6   \n",
       "4612     100.0                 100.0            64.1            98.9   \n",
       "\n",
       "      confidence_chunker  fit  spelling_mistakes  avg_sentence_len  \\\n",
       "0                   84.7  NaN               91.3              41.6   \n",
       "1                   88.2  NaN               87.5              18.7   \n",
       "2                   85.8  NaN              100.0              39.5   \n",
       "3                   91.3  NaN              100.0              50.0   \n",
       "4                   94.1  NaN              100.0              43.7   \n",
       "...                  ...  ...                ...               ...   \n",
       "4608                89.2  NaN              100.0              25.0   \n",
       "4609                96.6  NaN              100.0              39.0   \n",
       "4610                98.4  NaN               75.0              25.0   \n",
       "4611                92.4  NaN              100.0              28.1   \n",
       "4612                80.2  NaN               87.5              50.0   \n",
       "\n",
       "      perc_lowercase  perc_uppercase  lexical_diversity  recognized_by_pos  \\\n",
       "0                NaN             NaN               95.6               95.6   \n",
       "1                NaN             NaN               87.5              100.0   \n",
       "2                NaN             NaN               90.0               95.0   \n",
       "3                NaN             NaN               87.5              100.0   \n",
       "4                NaN             NaN               92.8              100.0   \n",
       "...              ...             ...                ...                ...   \n",
       "4608             NaN             NaN               92.8              100.0   \n",
       "4609             NaN             NaN               92.0              100.0   \n",
       "4610             NaN             NaN              100.0              100.0   \n",
       "4611             NaN             NaN              100.0              100.0   \n",
       "4612             NaN             NaN              100.0              100.0   \n",
       "\n",
       "      acronyms  present_in_dictionary  readability_cli  readability_ari  \n",
       "0        100.0                   86.9             92.5             94.6  \n",
       "1        100.0                   62.5             63.6             88.0  \n",
       "2        100.0                  100.0             63.2             63.3  \n",
       "3        100.0                   87.5             81.6             91.3  \n",
       "4        100.0                   92.8             87.0             98.0  \n",
       "...        ...                    ...              ...              ...  \n",
       "4608      85.7                   92.8             52.6             43.9  \n",
       "4609     100.0                   92.0             91.7             85.3  \n",
       "4610     100.0                   75.0             91.0             92.6  \n",
       "4611     100.0                   88.8             77.3             77.3  \n",
       "4612     100.0                   87.5             62.2             82.6  \n",
       "\n",
       "[4613 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_df = pd.DataFrame(indicatorsList, columns=list(indicatorsTemplate.keys()))\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 100. strings\n",
    "ind_df.replace({'100.': '100'}, regex=True, inplace=True)\n",
    "ind_df = ind_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsable</th>\n",
       "      <th>confidence_tokenizer</th>\n",
       "      <th>confidence_pos</th>\n",
       "      <th>confidence_ner</th>\n",
       "      <th>confidence_chunker</th>\n",
       "      <th>spelling_mistakes</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>recognized_by_pos</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>present_in_dictionary</th>\n",
       "      <th>readability_cli</th>\n",
       "      <th>readability_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.916649</td>\n",
       "      <td>97.026816</td>\n",
       "      <td>80.668134</td>\n",
       "      <td>98.45866</td>\n",
       "      <td>87.940408</td>\n",
       "      <td>94.797876</td>\n",
       "      <td>43.189718</td>\n",
       "      <td>94.817754</td>\n",
       "      <td>99.521396</td>\n",
       "      <td>98.422458</td>\n",
       "      <td>87.147236</td>\n",
       "      <td>75.989378</td>\n",
       "      <td>76.575996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parsable  confidence_tokenizer  confidence_pos  confidence_ner  \\\n",
       "0  97.916649             97.026816       80.668134        98.45866   \n",
       "\n",
       "   confidence_chunker  spelling_mistakes  avg_sentence_len  lexical_diversity  \\\n",
       "0           87.940408          94.797876         43.189718          94.817754   \n",
       "\n",
       "   recognized_by_pos   acronyms  present_in_dictionary  readability_cli  \\\n",
       "0          99.521396  98.422458              87.147236        75.989378   \n",
       "\n",
       "   readability_ari  \n",
       "0        76.575996  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of each column using DataFrame.mean()\n",
    "df2 = ind_df.mean(axis=0).to_frame()\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCsvName = cfg[\"uploadDir\"].replace(\"./data/corpora/sms_spam/\",\"\") + \".csv\"\n",
    "outputPath = os.path.join(cfg[\"resultDir\"],outputCsvName)\n",
    "df2.to_csv(outputPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20cb975c02109accbafa2be35d047791792b4e263bc20b6c63105d80068546e3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tesi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
